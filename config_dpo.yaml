policy_name: meta-llama/Llama-3.2-1B
ref_name: meta-llama/Llama-3.2-1B
precision: bf16

dataset:
  names:
    - hh                    # Anthropic Helpful-Harmless dataset
  split: train
  max_length: 512
  max_prompt_length: 256
  cache_dir: .cache
  
dpo_training:
  epochs: 1
  batch_size: 8
  beta: 0.1
  learning_rate: 1e-6
  log_steps: 10
  seed: 42



