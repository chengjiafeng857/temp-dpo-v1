policy_name: gpt2  # Or use: EleutherAI/pythia-160m, EleutherAI/pythia-410m
ref_name: gpt2
precision: bf16

dataset:
  names:
    - hh                    # Anthropic Helpful-Harmless dataset
  split: train
  max_length: 512
  max_prompt_length: 256
  cache_dir: .cache
  
dpo_training:
  epochs: 1
  batch_size: 8
  beta: 0.1
  learning_rate: 1e-6
  log_steps: 10
  seed: 42



