policy_name: meta-llama/Llama-3.2-1B
ref_name: meta-llama/Llama-3.2-1B
precision: bf16
mount_dir: "mounts/output"

dataset:
  dataset_name: Anthropic/hh-rlhf
  subset: train[:90%]
  val_ratio: 0.1
  seed: 42
  max_len: 256
  
dpo_training:
  epochs: 1
  batch_size: 8
  beta: 0.1
  learning_rate: 1e-6
  log_steps: 10

sft_training:
  enabled: true
  epochs: 1
  batch_size: 8
  eval_batch_size: 8
  learning_rate: 1e-5
  gradient_accumulation_steps: 8
  gradient_checkpointing: true
  log_steps: 5
  eval_steps: 100
  evaluation_strategy: steps
  dataloader_num_workers: 0
  debug_show_samples: true
  debug_samples: 5
  save_dir: ./logs/sft
  mount_save_dir: mounts/output/sft_model


